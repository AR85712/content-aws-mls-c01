{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Linux Academy](la-logo.png)\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>TensorFlow/Keras Basic Classification</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Sorting Lego bricks](./lego.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2>Lego Brick Sorting</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this Linux Academy Hands-on Lab we will be taking a introductory look at __TensorFlow__ (with __Keras__) and use it to make a simple artificial neural network.\n",
    "\n",
    "## TensorFlow\n",
    "\n",
    "TensorFlow (backed by Google) is an end-to-end open source platform for machine learning. It has a comprehensive, flexible ecosystem of tools, libraries and community resources that lets researchers push the state-of-the-art in ML and developers easily build and deploy ML powered applications.\n",
    "\n",
    "_(Source: https://www.tensorflow.org/)_\n",
    "\n",
    "## Keras\n",
    "\n",
    "Keras is a high-level neural networks API, written in Python and capable of running on top of TensorFlow, CNTK, or Theano. It was developed with a focus on enabling fast experimentation. Being able to go from idea to result with the least possible delay is key to doing good research.\n",
    "\n",
    "_(Source: https://keras.io/)_\n",
    "\n",
    "___Or, to put it another way:___\n",
    "\n",
    "TensorFlow is a complex tool.  Keras has been built ontop of TensorFlow as a more user-friendly interface.  It helps us to rapidly prototype models, and we will be using it in this lab.\n",
    "\n",
    "\n",
    "# Scenario\n",
    "\n",
    "We have bricks, lots of brick, Lego bricks that is.  And we need to get them sorted.\n",
    "\n",
    "We have a collection of photos of different Lego bricks from different angles.  We have 600 photos (no, really we do) and they are all labeled with the name of the brick.\n",
    "\n",
    "Each photo has been processed, including: increasing the contrast, sharpening, removing the color, inverting the colors, and reducing in size.\n",
    "\n",
    "|![Sample Lego brick photo](./sample-before.png)|![Sample Lego brick photo](./sample-after.png)|\n",
    "|----------------------------------------|----------------------------------------|\n",
    "| Sample before processing                | Sample after processing                |\n",
    "\n",
    "In addition to this, we have loaded all the images into a single data array for easier loading into algorithm.  _If you're interested in how these images were collected and processed contact me through the Linux Academy Community Slack:_ ```@mike chambers```\n",
    "\n",
    "We're going to create a simple, deep learning, neural network classifier model.  We will train the model using the photo data and see if it will correctly predict (or infer) the type of a brick from a supplied test image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Use This Lab\n",
    "\n",
    "This is a follow along lab.  That is to say that the code in this Jupyter Notebook should be complete, and you could simply execute the notebook and get a result.  However, watch along with the video to learn more about what is happening in the code, and then take the time to experiment with the code, make changes, break it, fix it, learn!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) The Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Load the data [numpy]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a dataset created from a set of photos of Lego bricks.  In total we have 4 arrays of data that have been saved to files as NumPy arrays.\n",
    "\n",
    "1. lego-simple-train-images.npy - _Training images, around 80% of the data collected._\n",
    "2. lego-simple-train-labels.npy - _A list of (integer) labels that identifiy the classes of the training images._\n",
    "3. lego-simple-test-images.npy  - _Testing images, around 20% of the data collected._\n",
    "4. lego-simple-test-labels.npy  - _A list of (integer) labels that identifiy the classes of the testing images._ \n",
    "\n",
    "First we load the data into runtime arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = np.load('lego-simple-train-images.npy')\n",
    "train_labels = np.load('lego-simple-train-labels.npy')\n",
    "test_images = np.load('lego-simple-test-images.npy')\n",
    "test_labels = np.load('lego-simple-test-labels.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The label data we have loaded are integer values (1,2,3) lets get some human names for the data classes we're working with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For humans:\n",
    "class_names = ['2x3 Brick', '2x2 Brick', '1x3 Brick', '2x1 Brick', '1x1 Brick', '2x2 Macaroni', '2x2 Curved End', 'Cog 16 Tooth', '1x2 Handles', '1x2 Grill']\n",
    "\n",
    "# Or the real Lego codes:\n",
    "# class_names = ['3002', '3003', '3622', '3004', '3005', '3063', '47457', '94925', '3839a', '2412b']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is loaded but it's nice to be able to see it.  Let's take a look at one of the images loaded with the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(train_images[0])\n",
    "plt.colorbar()\n",
    "plt.xlabel(class_names[train_labels[0]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at some more of the data, and make the formating a little nicer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "for i in range(20):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[train_labels[i]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Training [TensorFlow Keras]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the data is loaded, lets start training.  First we need to create a model. We are creating an artificail neural network.  It will have 3 layers:\n",
    "\n",
    "1. The input layer with enough nodes for our image data\n",
    "2. A hidden layer with 128 nodes\n",
    "3. An output player with 10 nodes, one for each of the classes we want to identify\n",
    "\n",
    "Each layer is densly connected, meaning tht each neuron in one layer is connected to ever neuron in the next layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(48, 48)),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to complie the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finnaly its time to train the model.  Note the 'epochs', and watch the accuracy as the it processes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_images, train_labels, epochs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see from the output above that with each epoch the model gets a greater accuracy (acc) score.  When we trained the model we stored the ```history``` of the training in a variable so we can draw a graph of how the training process progressed.  We can plot accuracy and loss over the epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "# Plot training accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "# Plot training loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Testing and Analysis [scikit-learn]\n",
    "\n",
    "Accuracy while training is one thing, let's calculate accuracy against the __testing data__.  If the accuracy achived during training is much greater than what we calculate fot the testing data the model is (probably) over fit, meaning it works well to classify training data, but not testing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Try some predictions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use our model to make some predictions using our testing data.  Remember the model hasn't 'seen' our testing data, not during training anyway, so when we make predictions using testing images its doing real work:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are a couple of functions to help with the display of the prediction data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display the image:\n",
    "\n",
    "def plot_image(i, predictions_array, true_label, img):\n",
    "  predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  plt.imshow(img, cmap=plt.cm.binary)\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "  if predicted_label == true_label:\n",
    "    color = 'green'\n",
    "  else:\n",
    "    color = 'red'\n",
    "  # Print a label with 'predicted class', 'probability %', 'actual class'\n",
    "  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                100*np.max(predictions_array),\n",
    "                                class_names[true_label]),\n",
    "                                color=color)\n",
    "\n",
    "# Function to display the prediction results in a graph:\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "  predictions_array, true_label = predictions_array[i], true_label[i]\n",
    "  plt.xticks(range(10))\n",
    "  plt.yticks([])\n",
    "  plot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
    "  plt.ylim([0, 1])\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "  plot[predicted_label].set_color('red')\n",
    "  plot[true_label].set_color('green')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets grab one of the images from the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_number = 8\n",
    "\n",
    "img = test_images[test_image_number]\n",
    "plt.figure()\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.imshow(img, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to do a quick transformation of the image data as the ```predict``` method is expecting a list of images, so we make a list of one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = (np.expand_dims(img,0))\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we pass our image to the ```predict``` method.  The result is a list of probabilities that the image is a certain class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_single = model.predict(img)\n",
    "predictions_single"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy has a handy function to find the largest value in the list (which saves us having to look :) ). We can use the value it finds, to look-up the label that's been predicted for this image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_result = np.argmax(predictions_single[0])\n",
    "class_names[prediction_result]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did we get it right?  Lets look up the class name for the test image (i.e. the real class name, not the predicted one, but we hope its the same!)  Did the model get it right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names[test_labels[test_image_number]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot a bar chart (using the helper function we defined at the start of this section) so we can get a sence of how well the model classified this image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_value_array(0, predictions_single, [test_labels[test_image_number]])\n",
    "plt.xticks(range(10), class_names, rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets get prediction values for ALL the test images we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally let's use our helper functions to summarise the first 16 images in our test data.  How did we do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = 8\n",
    "num_cols = 2\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(15, 16))\n",
    "for i in range(num_images):\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "  plot_image(i, predictions, test_labels, test_images)\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "  plot_value_array(i, predictions, test_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is the end of this Linux Academy Hands-on Lab.  Thanks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
